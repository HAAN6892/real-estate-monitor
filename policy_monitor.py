"""
ì •ì±… ë³€ê²½ ê°ì§€ ë°°ì¹˜
- ì£¼íƒë„ì‹œê¸°ê¸ˆ / ê¸ˆìœµìœ„ì›íšŒ / êµ­í† êµí†µë¶€ ê³µì‹ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
- í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê´€ë ¨ ê³µì§€ë§Œ í•„í„°ë§
- ìƒˆ ê³µì§€ ê°ì§€ ì‹œ í…”ë ˆê·¸ë¨ ì•Œë¦¼
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime, timezone, timedelta

CONFIG_PATH = "config.json"
CACHE_PATH = "policy_cache.json"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                  " (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
}

SOURCES = {
    "ì£¼íƒë„ì‹œê¸°ê¸ˆ": {
        "url": "https://nhuf.molit.go.kr/FP/FP08/FP0804/FP080402.jsp?id=3&mode=L",
        "base_url": "https://nhuf.molit.go.kr",
        "icon": "ğŸ ",
    },
    "ê¸ˆìœµìœ„ì›íšŒ": {
        "url": "https://www.fsc.go.kr/no010101",
        "base_url": "https://www.fsc.go.kr",
        "icon": "ğŸ¦",
    },
    "êµ­í† êµí†µë¶€": {
        "url": "https://www.molit.go.kr/USR/NEWS/m_71/lst.jsp",
        "base_url": "https://www.molit.go.kr/USR/NEWS/m_71/",
        "icon": "ğŸ—ï¸",
    },
}

KEYWORDS = [
    "LTV", "DSR", "ëŒ€ì¶œ", "ë‹´ë³´", "ë²„íŒ€ëª©", "ë””ë”¤ëŒ", "ë³´ê¸ˆìë¦¬",
    "ì‹ ìƒì•„", "ì‹ í˜¼", "ì „ì„¸", "ê·œì œì§€ì—­", "íˆ¬ê¸°ê³¼ì—´", "ì¡°ì •ëŒ€ìƒ",
    "ì£¼íƒë‹´ë³´", "ì£¼íƒêµ¬ì…", "ê¸ˆë¦¬", "ì†Œë“ê¸°ì¤€", "í•œë„",
    "ë¶€ë™ì‚° ëŒ€ì±…", "ê°€ê³„ë¶€ì±„",
]

# â”€â”€ ì„¤ì • / ìºì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_config():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)


def load_cache():
    try:
        with open(CACHE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {"last_checked": None, "sources": {}}


def save_cache(cache):
    with open(CACHE_PATH, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)


# â”€â”€ í¬ë¡¤ë§ í•¨ìˆ˜ (ì†ŒìŠ¤ë³„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_nhuf():
    """ì£¼íƒë„ì‹œê¸°ê¸ˆ ê³µì§€ì‚¬í•­"""
    src = SOURCES["ì£¼íƒë„ì‹œê¸°ê¸ˆ"]
    resp = requests.get(src["url"], headers=HEADERS, timeout=30)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    items = []
    for row in soup.select("table tbody tr"):
        title_tag = row.select_one("td.subject a")
        date_tag = row.select_one("td.date")
        if not title_tag:
            continue
        title = title_tag.get_text(strip=True)
        href = title_tag.get("href", "")
        link = src["base_url"] + href if href.startswith("/") else href
        date = date_tag.get_text(strip=True) if date_tag else ""
        items.append({"title": title, "date": date, "url": link})
    return items


def fetch_fsc():
    """ê¸ˆìœµìœ„ì›íšŒ ë³´ë„ìë£Œ"""
    src = SOURCES["ê¸ˆìœµìœ„ì›íšŒ"]
    resp = requests.get(src["url"], headers=HEADERS, timeout=30)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    items = []
    for li in soup.select("div.board-list-wrap ul > li"):
        title_tag = li.select_one("div.subject a")
        date_tag = li.select_one("div.day")
        if not title_tag:
            continue
        title = title_tag.get("title", "") or title_tag.get_text(strip=True)
        href = title_tag.get("href", "")
        link = src["base_url"] + href if href.startswith("/") else href
        date = date_tag.get_text(strip=True) if date_tag else ""
        items.append({"title": title, "date": date, "url": link})
    return items


def fetch_molit():
    """êµ­í† êµí†µë¶€ ë³´ë„ìë£Œ"""
    src = SOURCES["êµ­í† êµí†µë¶€"]
    session = requests.Session()
    session.headers.update(HEADERS)
    resp = session.get(src["url"], timeout=30)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    items = []
    for row in soup.select("table.bd_tbl tbody tr"):
        title_tag = row.select_one("td.bd_title a")
        date_tag = row.select_one("td.bd_date")
        if not title_tag:
            continue
        title = title_tag.get_text(strip=True)
        href = title_tag.get("href", "")
        link = src["base_url"] + href if not href.startswith("http") else href
        date = date_tag.get_text(strip=True) if date_tag else ""
        items.append({"title": title, "date": date, "url": link})
    return items


FETCHERS = {
    "ì£¼íƒë„ì‹œê¸°ê¸ˆ": fetch_nhuf,
    "ê¸ˆìœµìœ„ì›íšŒ": fetch_fsc,
    "êµ­í† êµí†µë¶€": fetch_molit,
}

# â”€â”€ í‚¤ì›Œë“œ ë§¤ì¹­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def matches_keyword(title):
    upper = title.upper()
    return any(kw.upper() in upper for kw in KEYWORDS)


# â”€â”€ í…”ë ˆê·¸ë¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def send_telegram(bot_token, chat_id, message):
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": message,
        "disable_web_page_preview": True,
    }
    try:
        resp = requests.post(url, json=payload, timeout=10)
        if resp.status_code == 200:
            print("  âœ… í…”ë ˆê·¸ë¨ ì „ì†¡ ì„±ê³µ")
        else:
            print(f"  âŒ í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {resp.status_code}")
    except Exception as e:
        print(f"  âŒ í…”ë ˆê·¸ë¨ ì „ì†¡ ì˜¤ë¥˜: {e}")


# â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    kst = timezone(timedelta(hours=9))
    now_kst = datetime.now(kst)
    print("=" * 50)
    print("ğŸ“‹ ì •ì±… ë³€ê²½ ê°ì§€ ë°°ì¹˜ ì‹œì‘")
    print(f"â° {now_kst.strftime('%Y-%m-%d %H:%M KST')}")
    print("=" * 50)

    config = load_config()
    bot_token = config["telegram"]["bot_token"]
    chat_id = config["telegram"]["chat_id"]

    cache = load_cache()
    is_first_run = cache["last_checked"] is None
    if is_first_run:
        print("\nğŸ†• ì²« ì‹¤í–‰ â€” í˜„ì¬ ê³µì§€ë¥¼ ìºì‹œì— ì €ì¥ë§Œ í•©ë‹ˆë‹¤ (ì•Œë¦¼ ì—†ìŒ)")

    new_items_by_source = {}
    errors = []

    for source_name, fetch_fn in FETCHERS.items():
        icon = SOURCES[source_name]["icon"]
        print(f"\n{icon} {source_name} í¬ë¡¤ë§ ì¤‘...")
        try:
            raw = fetch_fn()
            print(f"  ìˆ˜ì§‘: {len(raw)}ê±´")

            filtered = [it for it in raw if matches_keyword(it["title"])]
            print(f"  í‚¤ì›Œë“œ ë§¤ì¹­: {len(filtered)}ê±´")

            cached_urls = set(cache.get("sources", {}).get(source_name, []))
            new = [it for it in filtered if it["url"] not in cached_urls]
            print(f"  ì‹ ê·œ: {len(new)}ê±´")

            if new and not is_first_run:
                new_items_by_source[source_name] = new

            # ìºì‹œ: ê¸°ì¡´ URL + ìƒˆ URL (ìµœëŒ€ 500ê±´)
            all_urls = list(cached_urls | {it["url"] for it in filtered})
            cache.setdefault("sources", {})[source_name] = all_urls[-500:]
        except Exception as e:
            print(f"  âš ï¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            errors.append(f"{source_name}: {e}")

    # ìƒˆ í•­ëª© ì•Œë¦¼
    if new_items_by_source:
        lines = ["ğŸ“‹ ë¶€ë™ì‚° ì •ì±… ë³€ê²½ ê°ì§€", ""]
        for src, items in new_items_by_source.items():
            icon = SOURCES[src]["icon"]
            lines.append(f"ğŸ”” {src}")
            for it in items:
                lines.append(f"â€¢ {it['title']} ({it['date']})")
                lines.append(f"  â†’ {it['url']}")
            lines.append("")
        lines.append("âš ï¸ í™•ì¸ í›„ ëŒ€ì‹œë³´ë“œ ë°˜ì˜ í•„ìš” ì‹œ Claude Codeë¡œ ìˆ˜ì •")
        send_telegram(bot_token, chat_id, "\n".join(lines))
    elif not is_first_run:
        print("\n  â„¹ï¸ ìƒˆë¡œìš´ ì •ì±… ê³µì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ì „ì²´ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì•Œë¦¼
    if len(errors) == len(FETCHERS):
        msg = "âš ï¸ ì •ì±… ëª¨ë‹ˆí„°ë§ ì „ì²´ ì‹¤íŒ¨\n\n" + "\n".join(f"â€¢ {e}" for e in errors)
        send_telegram(bot_token, chat_id, msg)

    cache["last_checked"] = now_kst.strftime("%Y-%m-%d %H:%M KST")
    save_cache(cache)

    total_new = sum(len(v) for v in new_items_by_source.values())
    print(f"\n{'=' * 50}")
    print(f"âœ… ì™„ë£Œ | ì‹ ê·œ: {total_new}ê±´ | ì—ëŸ¬: {len(errors)}ê±´")
    print(f"{'=' * 50}")


if __name__ == "__main__":
    main()
