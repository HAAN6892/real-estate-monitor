"""
ìˆ˜ë„ê¶Œ ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ëª¨ë‹ˆí„°ë§ ë´‡ v5
- êµ­í† êµí†µë¶€ ì‹¤ê±°ë˜ê°€ API ë°ì´í„° ìˆ˜ì§‘ (ë§¤ë§¤ + ì „ì›”ì„¸)
- ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¡œ ì•„íŒŒíŠ¸ ì¢Œí‘œ â†’ ìµœê·¼ì ‘ ì—­ ê±°ë¦¬ ê³„ì‚°
- ë™ì¼ ë‹¨ì§€ ë¬¶ê¸°, ê°€ê²©ëŒ€ë³„ ê·¸ë£¹í•‘, í‰ë‹¹ê°€ ê³„ì‚°
- í…”ë ˆê·¸ë¨: ê°„ì†Œí™” ì•Œë¦¼ (ìš”ì•½ + ëŒ€ì‹œë³´ë“œ ë§í¬)
- [v5] data-rent.json ì¶”ê°€, 22ê°œ ì§€ì—­ í™•ëŒ€
"""

import json
import math
import os
import requests
import urllib.parse
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta, timezone
from pathlib import Path

# â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€
BASE_DIR = Path(__file__).parent
CONFIG_PATH = BASE_DIR / "config.json"
HISTORY_PATH = BASE_DIR / "sent_history.json"
RENT_HISTORY_PATH = BASE_DIR / "sent_history_rent.json"
COORD_CACHE_PATH = BASE_DIR / "coord_cache.json"
APT_INFO_CACHE_PATH = BASE_DIR / "apt_info_cache.json"
DATA_JSON_PATH = BASE_DIR / "data.json"
DATA_RENT_JSON_PATH = BASE_DIR / "data-rent.json"

# â”€â”€â”€ ëŒ€ì‹œë³´ë“œ URL â”€â”€â”€
DASHBOARD_URL = "https://haan6892.github.io/real-estate-monitor/"

# â”€â”€â”€ ì‹ ë¶„ë‹¹ì„  + ì£¼ìš” ì§€í•˜ì² ì—­ ì¢Œí‘œ â”€â”€â”€
STATIONS = [
    # ì‹ ë¶„ë‹¹ì„ 
    {"name": "ê°•ë‚¨", "lat": 37.4979, "lon": 127.0276, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ì–‘ì¬", "lat": 37.4842, "lon": 127.0353, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ì–‘ì¬ì‹œë¯¼ì˜ìˆ²", "lat": 37.4700, "lon": 127.0386, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ì²­ê³„ì‚°ì…êµ¬", "lat": 37.4474, "lon": 127.0562, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "íŒêµ", "lat": 37.3948, "lon": 127.1112, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ì •ì", "lat": 37.3669, "lon": 127.1085, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ë¯¸ê¸ˆ", "lat": 37.3510, "lon": 127.1095, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ë™ì²œ", "lat": 37.3383, "lon": 127.1085, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ìˆ˜ì§€êµ¬ì²­", "lat": 37.3220, "lon": 127.0960, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ì„±ë³µ", "lat": 37.3114, "lon": 127.0786, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ìƒí˜„", "lat": 37.3005, "lon": 127.0653, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ê´‘êµì¤‘ì•™", "lat": 37.2886, "lon": 127.0492, "line": "ì‹ ë¶„ë‹¹ì„ "},
    {"name": "ê´‘êµ", "lat": 37.2831, "lon": 127.0446, "line": "ì‹ ë¶„ë‹¹ì„ "},
    # ë¶„ë‹¹ì„  ì£¼ìš”ì—­
    {"name": "ì•¼íƒ‘", "lat": 37.4112, "lon": 127.1272, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ì´ë§¤", "lat": 37.3952, "lon": 127.1275, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ì„œí˜„", "lat": 37.3845, "lon": 127.1237, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ìˆ˜ë‚´", "lat": 37.3775, "lon": 127.1155, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ì˜¤ë¦¬", "lat": 37.3397, "lon": 127.1090, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ì£½ì „", "lat": 37.3249, "lon": 127.1076, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ë³´ì •", "lat": 37.3127, "lon": 127.1084, "line": "ë¶„ë‹¹ì„ "},
    {"name": "êµ¬ì„±", "lat": 37.3005, "lon": 127.1085, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ëª¨ë€", "lat": 37.4321, "lon": 127.1293, "line": "ë¶„ë‹¹ì„ "},
    {"name": "íƒœí‰", "lat": 37.4431, "lon": 127.1268, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ì˜í†µ", "lat": 37.2507, "lon": 127.0569, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ë§í¬", "lat": 37.2444, "lon": 127.0467, "line": "ë¶„ë‹¹ì„ "},
    {"name": "ë§¤íƒ„ê¶Œì„ ", "lat": 37.2630, "lon": 127.0360, "line": "ë¶„ë‹¹ì„ "},
    # 8í˜¸ì„  (ì†¡íŒŒ/ê°•ë™)
    {"name": "ì ì‹¤", "lat": 37.5133, "lon": 127.1001, "line": "2í˜¸ì„ "},
    {"name": "ì„ì´Œ", "lat": 37.5056, "lon": 127.1070, "line": "8í˜¸ì„ "},
    {"name": "ì†¡íŒŒ", "lat": 37.5014, "lon": 127.1125, "line": "8í˜¸ì„ "},
    {"name": "ê°€ë½ì‹œì¥", "lat": 37.4926, "lon": 127.1183, "line": "8í˜¸ì„ "},
    {"name": "ë¬¸ì •", "lat": 37.4857, "lon": 127.1228, "line": "8í˜¸ì„ "},
    {"name": "ì¥ì§€", "lat": 37.4784, "lon": 127.1264, "line": "8í˜¸ì„ "},
    {"name": "ë³µì •", "lat": 37.4706, "lon": 127.1265, "line": "8í˜¸ì„ "},
    {"name": "ì‚°ì„±", "lat": 37.4573, "lon": 127.1498, "line": "8í˜¸ì„ "},
    {"name": "ë‚¨í•œì‚°ì„±ì…êµ¬", "lat": 37.4502, "lon": 127.1578, "line": "8í˜¸ì„ "},
    {"name": "ë‹¨ëŒ€ì˜¤ê±°ë¦¬", "lat": 37.4441, "lon": 127.1565, "line": "8í˜¸ì„ "},
    # 5í˜¸ì„  (ê°•ë™/í•˜ë‚¨)
    {"name": "ê°•ë™", "lat": 37.5354, "lon": 127.1320, "line": "5í˜¸ì„ "},
    {"name": "ë‘”ì´Œë™", "lat": 37.5271, "lon": 127.1366, "line": "5í˜¸ì„ "},
    {"name": "ì˜¬ë¦¼í”½ê³µì›", "lat": 37.5165, "lon": 127.1312, "line": "5í˜¸ì„ "},
    {"name": "ë°©ì´", "lat": 37.5084, "lon": 127.1268, "line": "5í˜¸ì„ "},
    {"name": "ë¯¸ì‚¬", "lat": 37.5608, "lon": 127.1900, "line": "5í˜¸ì„ "},
    {"name": "í•˜ë‚¨í’ì‚°", "lat": 37.5519, "lon": 127.2048, "line": "5í˜¸ì„ "},
    {"name": "í•˜ë‚¨ì‹œì²­", "lat": 37.5393, "lon": 127.2149, "line": "5í˜¸ì„ "},
    {"name": "í•˜ë‚¨ê²€ë‹¨ì‚°", "lat": 37.5249, "lon": 127.2242, "line": "5í˜¸ì„ "},
    # 4í˜¸ì„  (ê³¼ì²œ/ì•ˆì–‘/êµ°í¬/ì˜ì™•)
    {"name": "ê³¼ì²œ", "lat": 37.4340, "lon": 126.9877, "line": "4í˜¸ì„ "},
    {"name": "ì •ë¶€ê³¼ì²œì²­ì‚¬", "lat": 37.4265, "lon": 126.9899, "line": "4í˜¸ì„ "},
    {"name": "ì¸ë•ì›", "lat": 37.4175, "lon": 126.9892, "line": "4í˜¸ì„ "},
    {"name": "í‰ì´Œ", "lat": 37.3947, "lon": 126.9635, "line": "4í˜¸ì„ "},
    {"name": "ë²”ê³„", "lat": 37.3898, "lon": 126.9515, "line": "4í˜¸ì„ "},
    {"name": "ê¸ˆì •", "lat": 37.3717, "lon": 126.9416, "line": "4í˜¸ì„ "},
    {"name": "ì‚°ë³¸", "lat": 37.3594, "lon": 126.9323, "line": "4í˜¸ì„ "},
    {"name": "ìˆ˜ë¦¬ì‚°", "lat": 37.3704, "lon": 126.9164, "line": "4í˜¸ì„ "},
    {"name": "ëŒ€ì•¼ë¯¸", "lat": 37.3805, "lon": 126.9074, "line": "4í˜¸ì„ "},
    {"name": "ì˜ì™•", "lat": 37.3447, "lon": 126.9688, "line": "1í˜¸ì„ "},
    # 3í˜¸ì„  (ê°•ë‚¨/ì„œì´ˆ)
    {"name": "êµëŒ€", "lat": 37.4937, "lon": 127.0146, "line": "3í˜¸ì„ "},
    {"name": "ë‚¨ë¶€í„°ë¯¸ë„", "lat": 37.4856, "lon": 127.0148, "line": "3í˜¸ì„ "},
    {"name": "ë§¤ë´‰", "lat": 37.4872, "lon": 127.0473, "line": "3í˜¸ì„ "},
    {"name": "ë„ê³¡", "lat": 37.4915, "lon": 127.0553, "line": "3í˜¸ì„ "},
    {"name": "ëŒ€ì¹˜", "lat": 37.4948, "lon": 127.0628, "line": "3í˜¸ì„ "},
    {"name": "í•™ì—¬ìš¸", "lat": 37.4969, "lon": 127.0713, "line": "3í˜¸ì„ "},
    {"name": "ëŒ€ì²­", "lat": 37.4921, "lon": 127.0818, "line": "3í˜¸ì„ "},
    {"name": "ì¼ì›", "lat": 37.4837, "lon": 127.0876, "line": "3í˜¸ì„ "},
    {"name": "ìˆ˜ì„œ", "lat": 37.4870, "lon": 127.1018, "line": "3í˜¸ì„ "},
    # 2í˜¸ì„  (ê°•ë‚¨)
    {"name": "ì—­ì‚¼", "lat": 37.5006, "lon": 127.0365, "line": "2í˜¸ì„ "},
    {"name": "ì„ ë¦‰", "lat": 37.5045, "lon": 127.0490, "line": "2í˜¸ì„ "},
    {"name": "ì‚¼ì„±", "lat": 37.5088, "lon": 127.0631, "line": "2í˜¸ì„ "},
    {"name": "ì¢…í•©ìš´ë™ì¥", "lat": 37.5108, "lon": 127.0735, "line": "2í˜¸ì„ "},
    {"name": "ì„œìš¸ëŒ€ì…êµ¬", "lat": 37.4812, "lon": 126.9527, "line": "2í˜¸ì„ "},
    {"name": "ë‚™ì„±ëŒ€", "lat": 37.4768, "lon": 126.9637, "line": "2í˜¸ì„ "},
    {"name": "ì‚¬ë‹¹", "lat": 37.4765, "lon": 126.9816, "line": "2í˜¸ì„ "},
    # ê²½ê°•ì„  (ê´‘ì£¼)
    {"name": "ì´ˆì›”", "lat": 37.3702, "lon": 127.2810, "line": "ê²½ê°•ì„ "},
    {"name": "ê³¤ì§€ì•”", "lat": 37.3381, "lon": 127.3230, "line": "ê²½ê°•ì„ "},
    {"name": "ì‹ ë‘”ë„ì˜ˆì´Œ", "lat": 37.3194, "lon": 127.3651, "line": "ê²½ê°•ì„ "},
    {"name": "ì´ì²œ", "lat": 37.2750, "lon": 127.4433, "line": "ê²½ê°•ì„ "},
    {"name": "ê²½ê¸°ê´‘ì£¼", "lat": 37.4090, "lon": 127.2540, "line": "ê²½ê°•ì„ "},
    # 7í˜¸ì„  (ê´‘ëª…/ë™ì‘/ê´€ì•…)
    {"name": "ì² ì‚°", "lat": 37.4752, "lon": 126.8680, "line": "7í˜¸ì„ "},
    {"name": "ê´‘ëª…ì‚¬ê±°ë¦¬", "lat": 37.4787, "lon": 126.8546, "line": "7í˜¸ì„ "},
    {"name": "ì´ìˆ˜", "lat": 37.4856, "lon": 126.9818, "line": "7í˜¸ì„ "},
    {"name": "ë‚´ë°©", "lat": 37.4874, "lon": 126.9903, "line": "7í˜¸ì„ "},
    {"name": "ìˆ­ì‹¤ëŒ€ì…êµ¬", "lat": 37.4966, "lon": 126.9537, "line": "7í˜¸ì„ "},
    # ê²½ì˜ì¤‘ì•™ì„  (êµ¬ë¦¬)
    {"name": "êµ¬ë¦¬", "lat": 37.5943, "lon": 127.1325, "line": "ê²½ì˜ì¤‘ì•™ì„ "},
    {"name": "ë„ë†", "lat": 37.5981, "lon": 127.1539, "line": "ê²½ì˜ì¤‘ì•™ì„ "},
    {"name": "ì–‘ì •", "lat": 37.5870, "lon": 127.1197, "line": "ê²½ì˜ì¤‘ì•™ì„ "},
    # 1í˜¸ì„  (ìˆ˜ì›)
    {"name": "ìˆ˜ì›", "lat": 37.2666, "lon": 127.0001, "line": "1í˜¸ì„ "},
    {"name": "í™”ì„œ", "lat": 37.2846, "lon": 126.9904, "line": "1í˜¸ì„ "},
    {"name": "ì„±ê· ê´€ëŒ€", "lat": 37.2994, "lon": 126.9720, "line": "1í˜¸ì„ "},
    # ì‹ ë¦¼ì„  (ê´€ì•…)
    {"name": "ì‹ ë¦¼", "lat": 37.4842, "lon": 126.9293, "line": "ì‹ ë¦¼ì„ "},
    {"name": "ê´€ì•…ì‚°", "lat": 37.4737, "lon": 126.9311, "line": "ì‹ ë¦¼ì„ "},
    # ë™ì‘êµ¬ ì¶”ê°€
    {"name": "ë…¸ëŸ‰ì§„", "lat": 37.5131, "lon": 126.9425, "line": "1í˜¸ì„ "},
    {"name": "ë™ì‘", "lat": 37.5010, "lon": 126.9518, "line": "4í˜¸ì„ "},
    {"name": "ì´ì‹ ëŒ€ì…êµ¬", "lat": 37.4870, "lon": 126.9818, "line": "4í˜¸ì„ "},
]


def load_config():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)


def load_history():
    if HISTORY_PATH.exists():
        with open(HISTORY_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


def save_history(history):
    history = history[-3000:]
    with open(HISTORY_PATH, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def load_rent_history():
    if RENT_HISTORY_PATH.exists():
        with open(RENT_HISTORY_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


def save_rent_history(history):
    history = history[-3000:]
    with open(RENT_HISTORY_PATH, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def load_coord_cache():
    if COORD_CACHE_PATH.exists():
        with open(COORD_CACHE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_coord_cache(cache):
    with open(COORD_CACHE_PATH, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)


def load_apt_info_cache():
    if APT_INFO_CACHE_PATH.exists():
        with open(APT_INFO_CACHE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_apt_info_cache(cache):
    with open(APT_INFO_CACHE_PATH, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)


# â”€â”€â”€ data.json / data-rent.json ë¡œë“œ/ì €ì¥ â”€â”€â”€
def load_data_json(path):
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"updated_at": "", "properties": []}


def save_data_json(data, path):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"  [data] {path.name} ì €ì¥ ì™„ë£Œ ({len(data['properties'])}ê±´)")


def fetch_region_apt_list(api_key, sigungu_code, apt_list_cache):
    if sigungu_code in apt_list_cache:
        return apt_list_cache[sigungu_code]

    url = "https://apis.data.go.kr/1613000/AptListService3/getSigunguAptList3"
    all_items = []
    page = 1

    while True:
        params = {
            "serviceKey": api_key,
            "sigunguCode": sigungu_code,
            "numOfRows": "200",
            "pageNo": str(page),
            "type": "json"
        }
        try:
            resp = requests.get(url, params=params, timeout=15)
            data = resp.json()
            items = data.get("response", {}).get("body", {}).get("items", [])
            if not items:
                break
            if isinstance(items, dict):
                items = [items]
            all_items.extend(items)
            total = data.get("response", {}).get("body", {}).get("totalCount", 0)
            if len(all_items) >= total:
                break
            page += 1
        except Exception as e:
            print(f"    [ëª©ë¡ì¡°íšŒ ì‹¤íŒ¨] {sigungu_code}: {e}")
            break

    apt_list_cache[sigungu_code] = all_items
    print(f"    [ëª©ë¡] {sigungu_code}: {len(all_items)}ê°œ ë‹¨ì§€ ë¡œë“œ")
    return all_items


def find_kapt_code(apt_name, apt_list):
    def clean(name):
        return name.replace(" ", "").replace("(", "").replace(")", "").lower()

    clean_name = clean(apt_name)

    for apt in apt_list:
        if clean(apt.get("kaptName", "")) == clean_name:
            return apt["kaptCode"]

    for apt in apt_list:
        kname = clean(apt.get("kaptName", ""))
        if clean_name in kname or kname in clean_name:
            return apt["kaptCode"]

    name_words = [w for w in clean_name if len(w) >= 2]
    best_score = 0
    best_code = None
    for apt in apt_list:
        kname = clean(apt.get("kaptName", ""))
        score = sum(1 for w in name_words if w in kname)
        if score > best_score:
            best_score = score
            best_code = apt["kaptCode"]

    if best_score >= 2:
        return best_code

    return None


def get_apt_household_count(api_key, apt_name, sigungu_code, apt_info_cache, apt_list_cache):
    cache_key = f"{sigungu_code}_{apt_name}"
    if cache_key in apt_info_cache:
        return apt_info_cache[cache_key]

    apt_list = fetch_region_apt_list(api_key, sigungu_code, apt_list_cache)
    kapt_code = find_kapt_code(apt_name, apt_list)

    if not kapt_code:
        print(f"    [ì„¸ëŒ€ìˆ˜] {apt_name}: ë‹¨ì§€ì½”ë“œ ëª» ì°¾ìŒ")
        result = {"ì„¸ëŒ€ìˆ˜": 0, "ë‹¨ì§€ì½”ë“œ": ""}
        apt_info_cache[cache_key] = result
        return result

    url = "https://apis.data.go.kr/1613000/AptBasisInfoServiceV4/getAphusBassInfoV4"
    params = {
        "serviceKey": api_key,
        "kaptCode": kapt_code,
        "type": "json"
    }

    try:
        resp = requests.get(url, params=params, timeout=10)
        data = resp.json()
        item = data.get("response", {}).get("body", {}).get("item", {})
        household = int(float(item.get("kaptdaCnt", 0) or 0))
        result = {"ì„¸ëŒ€ìˆ˜": household, "ë‹¨ì§€ì½”ë“œ": kapt_code}
        apt_info_cache[cache_key] = result
        print(f"    [ì„¸ëŒ€ìˆ˜] {apt_name} â†’ {household}ì„¸ëŒ€")
        return result

    except Exception as e:
        print(f"    [ì„¸ëŒ€ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨] {apt_name}: {e}")

    result = {"ì„¸ëŒ€ìˆ˜": 0, "ë‹¨ì§€ì½”ë“œ": kapt_code}
    apt_info_cache[cache_key] = result
    return result


# â”€â”€â”€ ë§¤ë§¤ ì‹¤ê±°ë˜ API â”€â”€â”€
def fetch_trades(api_key, region_code, deal_ymd):
    url = "https://apis.data.go.kr/1613000/RTMSDataSvcAptTradeDev/getRTMSDataSvcAptTradeDev"
    params = {
        "serviceKey": api_key,
        "LAWD_CD": region_code,
        "DEAL_YMD": deal_ymd,
        "pageNo": "1",
        "numOfRows": "9999"
    }

    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"  [ì˜¤ë¥˜] ë§¤ë§¤ API í˜¸ì¶œ ì‹¤íŒ¨ ({region_code}): {e}")
        return []

    try:
        root = ET.fromstring(response.text)
    except ET.ParseError:
        print(f"  [ì˜¤ë¥˜] XML íŒŒì‹± ì‹¤íŒ¨ ({region_code})")
        return []

    result_code = root.findtext(".//resultCode")
    if result_code and result_code not in ("00", "000"):
        result_msg = root.findtext(".//resultMsg", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        print(f"  [ì˜¤ë¥˜] API ì—ëŸ¬ ({region_code}): {result_msg}")
        return []

    items = root.findall(".//item")
    trades = []

    for item in items:
        try:
            trade = {
                "ì•„íŒŒíŠ¸": (item.findtext("aptNm") or "").strip(),
                "ë©´ì ": float(item.findtext("excluUseAr") or 0),
                "ê±°ë˜ê¸ˆì•¡": int((item.findtext("dealAmount") or "0").strip().replace(",", "")),
                "ì¸µ": int(item.findtext("floor") or 0),
                "ê±´ì¶•ë…„ë„": int(item.findtext("buildYear") or 0),
                "ê±°ë˜ë…„ë„": int(item.findtext("dealYear") or 0),
                "ê±°ë˜ì›”": int(item.findtext("dealMonth") or 0),
                "ê±°ë˜ì¼": int(item.findtext("dealDay") or 0),
                "ë²•ì •ë™": (item.findtext("umdNm") or "").strip(),
                "ì§€ë²ˆ": (item.findtext("jibun") or "").strip(),
                "ë„ë¡œëª…": (item.findtext("roadNm") or "").strip(),
            }
            trades.append(trade)
        except (ValueError, TypeError):
            continue

    return trades


# â”€â”€â”€ ì „ì›”ì„¸ ì‹¤ê±°ë˜ API â”€â”€â”€
def fetch_rent_trades(api_key, region_code, deal_ymd):
    """êµ­í† ë¶€ ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ API í˜¸ì¶œ"""
    url = "https://apis.data.go.kr/1613000/RTMSDataSvcAptRent/getRTMSDataSvcAptRent"
    params = {
        "serviceKey": api_key,
        "LAWD_CD": region_code,
        "DEAL_YMD": deal_ymd,
        "pageNo": "1",
        "numOfRows": "9999"
    }

    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"  [ì˜¤ë¥˜] ì „ì›”ì„¸ API í˜¸ì¶œ ì‹¤íŒ¨ ({region_code}): {e}")
        return []

    try:
        root = ET.fromstring(response.text)
    except ET.ParseError:
        print(f"  [ì˜¤ë¥˜] ì „ì›”ì„¸ XML íŒŒì‹± ì‹¤íŒ¨ ({region_code})")
        return []

    result_code = root.findtext(".//resultCode")
    if result_code and result_code not in ("00", "000"):
        result_msg = root.findtext(".//resultMsg", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        print(f"  [ì˜¤ë¥˜] ì „ì›”ì„¸ API ì—ëŸ¬ ({region_code}): {result_msg}")
        return []

    items = root.findall(".//item")
    trades = []

    for item in items:
        try:
            # ë³´ì¦ê¸ˆ(ë§Œì›), ì›”ì„¸(ë§Œì›)
            deposit = int((item.findtext("deposit") or "0").strip().replace(",", ""))
            monthly_rent = int((item.findtext("monthlyRent") or "0").strip().replace(",", ""))

            trade = {
                "ì•„íŒŒíŠ¸": (item.findtext("aptNm") or "").strip(),
                "ë©´ì ": float(item.findtext("excluUseAr") or 0),
                "ë³´ì¦ê¸ˆ": deposit,
                "ì›”ì„¸": monthly_rent,
                "ì „ì›”ì„¸êµ¬ë¶„": "ì „ì„¸" if monthly_rent == 0 else "ì›”ì„¸",
                "ì¸µ": int(item.findtext("floor") or 0),
                "ê±´ì¶•ë…„ë„": int(item.findtext("buildYear") or 0),
                "ê±°ë˜ë…„ë„": int(item.findtext("dealYear") or 0),
                "ê±°ë˜ì›”": int(item.findtext("dealMonth") or 0),
                "ê±°ë˜ì¼": int(item.findtext("dealDay") or 0),
                "ë²•ì •ë™": (item.findtext("umdNm") or "").strip(),
                "ì§€ë²ˆ": (item.findtext("jibun") or "").strip(),
                "ë„ë¡œëª…": (item.findtext("roadNm") or "").strip(),
                "ê³„ì•½ê¸°ê°„": (item.findtext("contractTerm") or "").strip(),
                "ê°±ì‹ ì—¬ë¶€": (item.findtext("renewalUseYn") or "").strip(),
                "ì´ì „ë³´ì¦ê¸ˆ": (item.findtext("preDeposit") or "").strip(),
                "ì´ì „ì›”ì„¸": (item.findtext("preMonthlyRent") or "").strip(),
            }
            trades.append(trade)
        except (ValueError, TypeError):
            continue

    return trades


def filter_trades(trades, filters):
    filtered = []
    today = datetime.now().date()
    max_days = filters.get("max_days_ago", 14)

    for t in trades:
        try:
            trade_date = datetime(t["ê±°ë˜ë…„ë„"], t["ê±°ë˜ì›”"], t["ê±°ë˜ì¼"]).date()
            if (today - trade_date).days > max_days:
                continue
        except (ValueError, TypeError):
            continue

        if t["ë©´ì "] < filters["min_area"] or t["ë©´ì "] > filters["max_area"]:
            continue
        if t["ê±°ë˜ê¸ˆì•¡"] < filters["min_price"] or t["ê±°ë˜ê¸ˆì•¡"] > filters["max_price"]:
            continue
        if t["ì¸µ"] < filters.get("min_floor", 1):
            continue
        max_by = filters.get("max_build_year", 9999)
        if max_by != 9999 and t["ê±´ì¶•ë…„ë„"] > max_by:
            continue
        filtered.append(t)
    return filtered


def filter_rent_trades(trades, filters):
    """ì „ì›”ì„¸ ê±°ë˜ í•„í„°ë§"""
    filtered = []
    today = datetime.now().date()
    max_days = filters.get("max_days_ago", 30)  # ì „ì„¸ëŠ” 30ì¼ë¡œ ë„“ê²Œ

    rent_filters = filters.get("rent", {})
    min_deposit = rent_filters.get("min_deposit", 0)
    max_deposit = rent_filters.get("max_deposit", 100000)  # ê¸°ë³¸ 10ì–µ
    rent_type = rent_filters.get("type", "all")  # all, ì „ì„¸, ì›”ì„¸

    for t in trades:
        try:
            trade_date = datetime(t["ê±°ë˜ë…„ë„"], t["ê±°ë˜ì›”"], t["ê±°ë˜ì¼"]).date()
            if (today - trade_date).days > max_days:
                continue
        except (ValueError, TypeError):
            continue

        if t["ë©´ì "] < filters["min_area"] or t["ë©´ì "] > filters["max_area"]:
            continue
        if t["ë³´ì¦ê¸ˆ"] < min_deposit or t["ë³´ì¦ê¸ˆ"] > max_deposit:
            continue
        if t["ì¸µ"] < filters.get("min_floor", 1):
            continue
        if rent_type != "all" and t["ì „ì›”ì„¸êµ¬ë¶„"] != rent_type:
            continue

        filtered.append(t)
    return filtered


def make_trade_id(trade, region_name):
    return f"{region_name}_{trade['ì•„íŒŒíŠ¸']}_{trade['ë©´ì ']}_{trade['ê±°ë˜ê¸ˆì•¡']}_{trade['ì¸µ']}_{trade['ê±°ë˜ë…„ë„']}{trade['ê±°ë˜ì›”']:02d}{trade['ê±°ë˜ì¼']:02d}"


def make_rent_trade_id(trade, region_name):
    return f"R_{region_name}_{trade['ì•„íŒŒíŠ¸']}_{trade['ë©´ì ']}_{trade['ë³´ì¦ê¸ˆ']}_{trade['ì›”ì„¸']}_{trade['ì¸µ']}_{trade['ê±°ë˜ë…„ë„']}{trade['ê±°ë˜ì›”']:02d}{trade['ê±°ë˜ì¼']:02d}"


# â”€â”€â”€ ì¹´ì¹´ì˜¤ APIë¡œ ì£¼ì†Œ â†’ ì¢Œí‘œ ë³€í™˜ â”€â”€â”€
def get_coordinates(kakao_key, address, coord_cache):
    if address in coord_cache:
        return coord_cache[address]

    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {kakao_key}"}
    params = {"query": address}

    try:
        resp = requests.get(url, headers=headers, params=params, timeout=5)
        data = resp.json()
        if data.get("documents"):
            doc = data["documents"][0]
            result = {"lat": float(doc["y"]), "lon": float(doc["x"])}
            coord_cache[address] = result
            return result
    except Exception:
        pass

    url2 = "https://dapi.kakao.com/v2/local/search/keyword.json"
    try:
        resp = requests.get(url2, headers=headers, params=params, timeout=5)
        data = resp.json()
        if data.get("documents"):
            doc = data["documents"][0]
            result = {"lat": float(doc["y"]), "lon": float(doc["x"])}
            coord_cache[address] = result
            return result
    except Exception:
        pass

    return None


def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    a = math.sin(dlat/2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon/2)**2
    return R * 2 * math.asin(math.sqrt(a))


def find_nearest_station(lat, lon):
    nearest = None
    min_dist = float("inf")
    for st in STATIONS:
        dist = haversine(lat, lon, st["lat"], st["lon"])
        if dist < min_dist:
            min_dist = dist
            nearest = st
    walk_min = round(min_dist * 15)
    return nearest, min_dist, walk_min


# â”€â”€â”€ í¬ë§·íŒ… í•¨ìˆ˜ â”€â”€â”€
def format_price(price_man):
    if price_man >= 10000:
        ì–µ = price_man // 10000
        ë‚˜ë¨¸ì§€ = price_man % 10000
        if ë‚˜ë¨¸ì§€ > 0:
            return f"{ì–µ}ì–µ {ë‚˜ë¨¸ì§€:,}"
        return f"{ì–µ}ì–µ"
    return f"{price_man:,}ë§Œ"


def to_pyeong(m2):
    return round(m2 / 3.3058, 1)


# â”€â”€â”€ ë‹¨ì§€ë³„ ë¬¶ê¸° â”€â”€â”€
def group_by_complex(trades):
    groups = {}
    for t in trades:
        key = f"{t['ì•„íŒŒíŠ¸']}_{t['ë©´ì ']}"
        if key not in groups:
            groups[key] = {
                "ì•„íŒŒíŠ¸": t["ì•„íŒŒíŠ¸"],
                "ë©´ì ": t["ë©´ì "],
                "ê±´ì¶•ë…„ë„": t["ê±´ì¶•ë…„ë„"],
                "ë²•ì •ë™": t["ë²•ì •ë™"],
                "ë„ë¡œëª…": t.get("ë„ë¡œëª…", ""),
                "ê±°ë˜": []
            }
        groups[key]["ê±°ë˜"].append(t)
    return groups


def group_rent_by_complex(trades):
    """ì „ì›”ì„¸ ê±°ë˜ë¥¼ ë‹¨ì§€ë³„ë¡œ ë¬¶ê¸°"""
    groups = {}
    for t in trades:
        key = f"{t['ì•„íŒŒíŠ¸']}_{t['ë©´ì ']}"
        if key not in groups:
            groups[key] = {
                "ì•„íŒŒíŠ¸": t["ì•„íŒŒíŠ¸"],
                "ë©´ì ": t["ë©´ì "],
                "ê±´ì¶•ë…„ë„": t["ê±´ì¶•ë…„ë„"],
                "ë²•ì •ë™": t["ë²•ì •ë™"],
                "ë„ë¡œëª…": t.get("ë„ë¡œëª…", ""),
                "ê±°ë˜": []
            }
        groups[key]["ê±°ë˜"].append(t)
    return groups


def build_region_data(region_name, complex_groups, kakao_key, coord_cache, sgg_name, api_key, apt_info_cache, min_households, region_code, apt_list_cache):
    """í•œ ì§€ì—­ì˜ ë§¤ë§¤ data.json ì €ì¥ìš© ë°ì´í„° ìƒì„±"""

    data_items = []
    skipped_small = 0

    for key, group in complex_groups.items():
        apt_info = get_apt_household_count(api_key, group["ì•„íŒŒíŠ¸"], region_code, apt_info_cache, apt_list_cache)
        household = apt_info["ì„¸ëŒ€ìˆ˜"]

        if household > 0 and household < min_households:
            skipped_small += 1
            continue

        trades = group["ê±°ë˜"]
        pyeong = to_pyeong(group["ë©´ì "])

        address = f"{sgg_name} {group['ë²•ì •ë™']} {group['ì•„íŒŒíŠ¸']}"
        coord = get_coordinates(kakao_key, address, coord_cache)

        walk_min = 999
        nearest_station_name = ""
        nearest_station_line = ""
        if coord:
            nearest, dist_km, walk_min = find_nearest_station(coord["lat"], coord["lon"])
            nearest_station_name = nearest["name"]
            nearest_station_line = nearest["line"]

        for t in trades:
            try:
                trade_date_str = f"{t['ê±°ë˜ë…„ë„']}-{t['ê±°ë˜ì›”']:02d}-{t['ê±°ë˜ì¼']:02d}"
            except (ValueError, TypeError):
                trade_date_str = ""

            search_query = urllib.parse.quote(f"{group['ë²•ì •ë™']} {group['ì•„íŒŒíŠ¸']}")
            naver_link = f"https://m.land.naver.com/search/result/{search_query}"

            data_items.append({
                "name": group["ì•„íŒŒíŠ¸"],
                "region": region_name,
                "dong": group["ë²•ì •ë™"],
                "area_m2": group["ë©´ì "],
                "area_py": pyeong,
                "price": t["ê±°ë˜ê¸ˆì•¡"],
                "price_per_py": round(t["ê±°ë˜ê¸ˆì•¡"] / pyeong) if pyeong > 0 else 0,
                "floor": t["ì¸µ"],
                "built_year": group["ê±´ì¶•ë…„ë„"],
                "households": household,
                "station": nearest_station_name,
                "line": nearest_station_line,
                "walk_min": walk_min if walk_min < 999 else None,
                "trade_date": trade_date_str,
                "link": naver_link,
                "regulated": False,
                "lat": coord["lat"] if coord else None,
                "lon": coord["lon"] if coord else None,
            })

    if skipped_small > 0:
        print(f"    â„¹ï¸ {min_households}ì„¸ëŒ€ ë¯¸ë§Œ {skipped_small}ê°œ ë‹¨ì§€ ì œì™¸")

    return data_items


def build_rent_region_data(region_name, complex_groups, kakao_key, coord_cache, sgg_name, api_key, apt_info_cache, min_households, region_code, apt_list_cache):
    """í•œ ì§€ì—­ì˜ ì „ì›”ì„¸ data-rent.json ì €ì¥ìš© ë°ì´í„° ìƒì„±"""

    data_items = []
    skipped_small = 0

    for key, group in complex_groups.items():
        apt_info = get_apt_household_count(api_key, group["ì•„íŒŒíŠ¸"], region_code, apt_info_cache, apt_list_cache)
        household = apt_info["ì„¸ëŒ€ìˆ˜"]

        if household > 0 and household < min_households:
            skipped_small += 1
            continue

        trades = group["ê±°ë˜"]
        pyeong = to_pyeong(group["ë©´ì "])

        address = f"{sgg_name} {group['ë²•ì •ë™']} {group['ì•„íŒŒíŠ¸']}"
        coord = get_coordinates(kakao_key, address, coord_cache)

        walk_min = 999
        nearest_station_name = ""
        nearest_station_line = ""
        if coord:
            nearest, dist_km, walk_min = find_nearest_station(coord["lat"], coord["lon"])
            nearest_station_name = nearest["name"]
            nearest_station_line = nearest["line"]

        for t in trades:
            try:
                trade_date_str = f"{t['ê±°ë˜ë…„ë„']}-{t['ê±°ë˜ì›”']:02d}-{t['ê±°ë˜ì¼']:02d}"
            except (ValueError, TypeError):
                trade_date_str = ""

            search_query = urllib.parse.quote(f"{group['ë²•ì •ë™']} {group['ì•„íŒŒíŠ¸']}")
            naver_link = f"https://m.land.naver.com/search/result/{search_query}"

            data_items.append({
                "name": group["ì•„íŒŒíŠ¸"],
                "region": region_name,
                "dong": group["ë²•ì •ë™"],
                "area_m2": group["ë©´ì "],
                "area_py": pyeong,
                "deposit": t["ë³´ì¦ê¸ˆ"],
                "monthly_rent": t["ì›”ì„¸"],
                "rent_type": t["ì „ì›”ì„¸êµ¬ë¶„"],
                "deposit_per_py": round(t["ë³´ì¦ê¸ˆ"] / pyeong) if pyeong > 0 else 0,
                "floor": t["ì¸µ"],
                "built_year": group["ê±´ì¶•ë…„ë„"],
                "households": household,
                "station": nearest_station_name,
                "line": nearest_station_line,
                "walk_min": walk_min if walk_min < 999 else None,
                "trade_date": trade_date_str,
                "contract_term": t.get("ê³„ì•½ê¸°ê°„", ""),
                "renewal": t.get("ê°±ì‹ ì—¬ë¶€", ""),
                "prev_deposit": t.get("ì´ì „ë³´ì¦ê¸ˆ", ""),
                "prev_monthly": t.get("ì´ì „ì›”ì„¸", ""),
                "link": naver_link,
                "lat": coord["lat"] if coord else None,
                "lon": coord["lon"] if coord else None,
            })

    if skipped_small > 0:
        print(f"    â„¹ï¸ ì „ì„¸: {min_households}ì„¸ëŒ€ ë¯¸ë§Œ {skipped_small}ê°œ ë‹¨ì§€ ì œì™¸")

    return data_items


# â”€â”€â”€ í…”ë ˆê·¸ë¨ ì „ì†¡ â”€â”€â”€
def send_telegram(bot_token, chat_id, message):
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = {"chat_id": chat_id, "text": message, "parse_mode": "Markdown", "disable_web_page_preview": True}
    try:
        resp = requests.post(url, json=payload, timeout=10)
        if resp.status_code != 200:
            print(f"  [ì˜¤ë¥˜] í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {resp.text}")
            return False
        return True
    except requests.exceptions.RequestException as e:
        print(f"  [ì˜¤ë¥˜] í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")
        return False


# â”€â”€â”€ ë©”ì¸ â”€â”€â”€
def main():
    print("=" * 50)
    print("ğŸ  ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ëª¨ë‹ˆí„°ë§ v5 (ë§¤ë§¤ + ì „ì›”ì„¸)")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)

    config = load_config()
    api_key = config["api_key"]
    bot_token = config["telegram"]["bot_token"]
    chat_id = config["telegram"]["chat_id"]
    kakao_key = config.get("kakao_key", "")
    filters = config["filters"]
    regions = config["regions"]

    history = load_history()
    history_set = set(history)
    rent_history = load_rent_history()
    rent_history_set = set(rent_history)
    coord_cache = load_coord_cache()
    apt_info_cache = load_apt_info_cache()
    apt_list_cache = {}
    min_households = filters.get("min_households", 200)

    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    existing_data = load_data_json(DATA_JSON_PATH)
    existing_properties = existing_data.get("properties", [])
    existing_keys = set()
    for p in existing_properties:
        key = f"{p['region']}_{p['name']}_{p['area_m2']}_{p['price']}_{p['floor']}_{p['trade_date']}"
        existing_keys.add(key)

    existing_rent_data = load_data_json(DATA_RENT_JSON_PATH)
    existing_rent_properties = existing_rent_data.get("properties", [])
    existing_rent_keys = set()
    for p in existing_rent_properties:
        key = f"{p['region']}_{p['name']}_{p['area_m2']}_{p['deposit']}_{p.get('monthly_rent',0)}_{p['floor']}_{p['trade_date']}"
        existing_rent_keys.add(key)

    KST = timezone(timedelta(hours=9))
    now = datetime.now(KST)
    months = [now.strftime("%Y%m"), (now - timedelta(days=30)).strftime("%Y%m")]
    months = list(dict.fromkeys(months))

    total_new_trade = 0
    total_new_rent = 0
    all_new_trade_items = []
    all_new_rent_items = []
    trade_region_results = {}
    rent_region_results = {}

    for region in regions:
        region_name = region["name"]
        region_code = region["code"]
        sgg_name = region.get("sgg_name", region_name)
        print(f"\nğŸ“ {region_name} ({region_code}) ì¡°íšŒ ì¤‘...")

        # â”€â”€ ë§¤ë§¤ ìˆ˜ì§‘ â”€â”€
        new_trades = []
        for month in months:
            print(f"  ğŸ“… ë§¤ë§¤ {month} ì¡°íšŒ...")
            trades = fetch_trades(api_key, region_code, month)
            print(f"  â†’ {len(trades)}ê±´ ì¡°íšŒë¨")
            filtered = filter_trades(trades, filters)
            print(f"  â†’ {len(filtered)}ê±´ í•„í„° í†µê³¼")

            for trade in filtered:
                trade_id = make_trade_id(trade, region_name)
                if trade_id in history_set:
                    continue
                new_trades.append(trade)
                history.append(trade_id)
                history_set.add(trade_id)
                total_new_trade += 1

        if new_trades:
            trade_region_results[region_name] = {"trades": new_trades, "sgg_name": sgg_name, "region_code": region_code}
            print(f"  âœ… ë§¤ë§¤ ìƒˆ ê±°ë˜ {len(new_trades)}ê±´")

        # â”€â”€ ì „ì›”ì„¸ ìˆ˜ì§‘ â”€â”€
        new_rents = []
        for month in months:
            print(f"  ğŸ“… ì „ì›”ì„¸ {month} ì¡°íšŒ...")
            rents = fetch_rent_trades(api_key, region_code, month)
            print(f"  â†’ {len(rents)}ê±´ ì¡°íšŒë¨")
            filtered_rents = filter_rent_trades(rents, filters)
            print(f"  â†’ {len(filtered_rents)}ê±´ í•„í„° í†µê³¼")

            for rent in filtered_rents:
                rent_id = make_rent_trade_id(rent, region_name)
                if rent_id in rent_history_set:
                    continue
                new_rents.append(rent)
                rent_history.append(rent_id)
                rent_history_set.add(rent_id)
                total_new_rent += 1

        if new_rents:
            rent_region_results[region_name] = {"trades": new_rents, "sgg_name": sgg_name, "region_code": region_code}
            print(f"  âœ… ì „ì›”ì„¸ ìƒˆ ê±°ë˜ {len(new_rents)}ê±´")

    # â”€â”€â”€ í…”ë ˆê·¸ë¨ ì•Œë¦¼ â”€â”€â”€
    if total_new_trade > 0 or total_new_rent > 0:
        trade_lines = []
        rent_lines = []

        for rname, rdata in trade_region_results.items():
            trade_lines.append(f"  â€¢ {rname}: {len(rdata['trades'])}ê±´")
        for rname, rdata in rent_region_results.items():
            rent_lines.append(f"  â€¢ {rname}: {len(rdata['trades'])}ê±´")

        parts = [
            f"ğŸ  *ë§¤ë¬¼ ì—…ë°ì´íŠ¸*",
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            f"â° {now.strftime('%Y-%m-%d %H:%M')}",
        ]

        if total_new_trade > 0:
            parts.append(f"\nğŸ”‘ ë§¤ë§¤ ì‹ ê·œ *{total_new_trade}ê±´*")
            parts.extend(trade_lines)

        if total_new_rent > 0:
            parts.append(f"\nğŸ˜ ì „ì›”ì„¸ ì‹ ê·œ *{total_new_rent}ê±´*")
            parts.extend(rent_lines)

        parts.append(f"\nğŸ“Š [ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸]({DASHBOARD_URL})")
        message = "\n".join(parts)
    else:
        message = (
            f"ğŸ  *ë§¤ë¬¼ ì—…ë°ì´íŠ¸*\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"â° {now.strftime('%Y-%m-%d %H:%M')}\n"
            f"ì‹ ê·œ ê±°ë˜ ì—†ìŒ\n\n"
            f"ğŸ“Š [ëŒ€ì‹œë³´ë“œ ë³´ê¸°]({DASHBOARD_URL})"
        )

    send_telegram(bot_token, chat_id, message)
    print(f"  ğŸ“¤ í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")

    # â”€â”€â”€ data.json (ë§¤ë§¤) ì—…ë°ì´íŠ¸ â”€â”€â”€
    if trade_region_results:
        for rname, rdata in trade_region_results.items():
            complex_groups = group_by_complex(rdata["trades"])
            data_items = build_region_data(
                rname, complex_groups, kakao_key, coord_cache,
                rdata["sgg_name"], api_key, apt_info_cache,
                min_households, rdata["region_code"], apt_list_cache
            )
            for item in data_items:
                item_key = f"{item['region']}_{item['name']}_{item['area_m2']}_{item['price']}_{item['floor']}_{item['trade_date']}"
                if item_key not in existing_keys:
                    all_new_trade_items.append(item)
                    existing_keys.add(item_key)

    all_properties = existing_properties + all_new_trade_items
    cutoff_date = (now - timedelta(days=90)).strftime("%Y-%m-%d")
    all_properties = [p for p in all_properties if p.get("trade_date", "9999") >= cutoff_date or not p.get("trade_date")]
    all_properties.sort(key=lambda x: x.get("trade_date", ""), reverse=True)

    save_data_json({
        "updated_at": now.strftime("%Y-%m-%d %H:%M"),
        "total_count": len(all_properties),
        "new_count": len(all_new_trade_items),
        "properties": all_properties
    }, DATA_JSON_PATH)

    # â”€â”€â”€ data-rent.json (ì „ì›”ì„¸) ì—…ë°ì´íŠ¸ â”€â”€â”€
    if rent_region_results:
        for rname, rdata in rent_region_results.items():
            complex_groups = group_rent_by_complex(rdata["trades"])
            data_items = build_rent_region_data(
                rname, complex_groups, kakao_key, coord_cache,
                rdata["sgg_name"], api_key, apt_info_cache,
                min_households, rdata["region_code"], apt_list_cache
            )
            for item in data_items:
                item_key = f"{item['region']}_{item['name']}_{item['area_m2']}_{item['deposit']}_{item.get('monthly_rent',0)}_{item['floor']}_{item['trade_date']}"
                if item_key not in existing_rent_keys:
                    all_new_rent_items.append(item)
                    existing_rent_keys.add(item_key)

    all_rent_properties = existing_rent_properties + all_new_rent_items
    all_rent_properties = [p for p in all_rent_properties if p.get("trade_date", "9999") >= cutoff_date or not p.get("trade_date")]
    all_rent_properties.sort(key=lambda x: x.get("trade_date", ""), reverse=True)

    save_data_json({
        "updated_at": now.strftime("%Y-%m-%d %H:%M"),
        "total_count": len(all_rent_properties),
        "new_count": len(all_new_rent_items),
        "properties": all_rent_properties
    }, DATA_RENT_JSON_PATH)

    # ì €ì¥
    save_history(history)
    save_rent_history(rent_history)
    save_coord_cache(coord_cache)
    save_apt_info_cache(apt_info_cache)

    print(f"\n{'=' * 50}")
    print(f"âœ… ì™„ë£Œ!")
    print(f"   ë§¤ë§¤: ìƒˆ {total_new_trade}ê±´ / ì´ {len(all_properties)}ê±´")
    print(f"   ì „ì›”ì„¸: ìƒˆ {total_new_rent}ê±´ / ì´ {len(all_rent_properties)}ê±´")
    print(f"{'=' * 50}")


if __name__ == "__main__":
    main()
